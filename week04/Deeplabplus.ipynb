{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deeplabplus.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ivvoyRehu6s"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.model_zoo as model_zoo"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XllS_a0fiA_o"
      },
      "source": [
        "bn_mom = 0.0003\n",
        "\n",
        "# 预先训练模型地址\n",
        "model_urls = {\n",
        "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
        "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
        "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth'\n",
        "}"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UkSZBjRiEBB"
      },
      "source": [
        "# 输入输出hw相同的膨胀卷积模块\n",
        "def conv3x3(in_ch, out_ch, stride=1, atrous=1):\n",
        "    return nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=stride, \\\n",
        "                padding=atrous, dilation=atrous, bias=False)\n",
        "    \n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "    def __init__(self, in_ch, out_ch, stride=1, atrous=1, downsample=None):\n",
        "        super().__init__()\n",
        "        self.conv1 = conv3x3(in_ch, out_ch, stride=stride, atrous=atrous)\n",
        "        self.bn1 = nn.BatchNorm2d(out_ch)\n",
        "        self.relu = nn.ReLU(True)\n",
        "        self.conv2 = conv3x3(out_ch, out_ch)\n",
        "        self.bn2 = nn.BatchNorm2d(out_ch)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        x = self.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.bn2(self.conv2(x))\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(residual)\n",
        "        x += residual\n",
        "        return self.relu(x)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuA0ZtSamOz3"
      },
      "source": [
        "# 膨胀卷积为基础卷积块的BottleNeck模块\n",
        "# BottleNeck模块一般是3次卷积，输出通道分别是in->out->out->out*expansion；这里正常情况下out<in<out*expansion\n",
        "# 3次卷积的卷积核大小为1x1->3x3->1x1；代替源码，使用conv3x3这个模块来实现卷积\n",
        "class BottleNeck(nn.Module):\n",
        "    expansion = 4\n",
        "    def __init__(self, in_ch, out_ch, stride=1, atrous=1, downsample=None):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_ch, out_ch, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_ch)\n",
        "        self.conv2 = conv3x3(out_ch, out_ch, stride=stride, atrous=atrous)\n",
        "        self.bn2 = nn.BatchNorm2d(out_ch)\n",
        "        self.relu = nn.ReLU(True)\n",
        "        self.conv3 = nn.Conv2d(out_ch, out_ch*self.expansion, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(out_ch*self.expansion)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        x = self.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.bn3(self.conv3(x))\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(residual)\n",
        "        x += residual\n",
        "        return self.relu(x)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJ733NNZZLSl",
        "outputId": "141bd9cc-991a-4088-f864-c3234fe11314"
      },
      "source": [
        "# 有膨胀卷积的Resnet网络；根据os的不同，输出大小/8或者/16\n",
        "class ResNet_Atrous(nn.Module):\n",
        "    # 当layers=[3,4,6,3]时，block为bottlenet时，就生成resnet50\n",
        "    def __init__(self, block, layers, atrous=None, os=16):\n",
        "        super(ResNet_Atrous, self).__init__()\n",
        "        self.block = block\n",
        "        stride_list = None\n",
        "        if os == 8:\n",
        "            # 控制block2,block3,block4的第一个bottleneck的3x3卷积的stride\n",
        "            # 这里指将block2内的第一个bottleneck的3x3卷集的stride设置为2\n",
        "            # 这里指将block3内的第一个bottleneck的3x3卷集的stride设置为1\n",
        "            # 这里指将block4内的第一个bottleneck的3x3卷集的stride设置为1\n",
        "            stride_list = [2, 1, 1]\n",
        "        elif os == 16:\n",
        "            stride_list = [2, 2, 1]\n",
        "        else:\n",
        "            raise ValueError('resnet_atrous.py: output stride=%d is not supported.' % os)\n",
        "\n",
        "        self.inplanes = 64\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        # resnet的 block1\n",
        "        self.layer1 = self._make_layer(block, 64, 64, layers[0]) # layer1并没有下采样处理！当前为1/4\n",
        "        # resnet的 block2\n",
        "        self.layer2 = self._make_layer(block, 64 * block.expansion, 128, layers[1], stride=stride_list[0]) # 1/8\n",
        "        # resnet的 block3\n",
        "        self.layer3 = self._make_layer(block, 128 * block.expansion, 256, layers[2], stride=stride_list[1], atrous=16 // os) # 2个3x3卷积的感受野和1个3x3,d=2的膨胀卷积一样\n",
        "        # resnet的 block4,block4的atrous为列表，里面使用了multi-grid技术\n",
        "        self.layer4 = self._make_layer(block, 256 * block.expansion, 512, layers[3], stride=stride_list[2],\n",
        "                                       atrous=[item * 16 // os for item in atrous])\n",
        "        self.layer5 = self._make_layer(block, 512 * block.expansion, 512, layers[3], stride=1, atrous=[item*16//os for item in atrous])\n",
        "        self.layer6 = self._make_layer(block, 512 * block.expansion, 512, layers[3], stride=1, atrous=[item*16//os for item in atrous])\n",
        "        self.layers = []\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def _make_layer(self, block, in_chans, out_chans, blocks, stride=1, atrous=None):\n",
        "        downsample = None\n",
        "        if atrous == None:\n",
        "            # 当没有设置atrous,blocks=3时，atrous=[1,1,1]\n",
        "            # 此时表示resnet的block1,或者block2,或者block3,或者block4内的bottleneck中的3x3卷积的膨胀系数为1，\n",
        "            # 膨胀系数为1，就表示没有膨胀，还是标准卷积。\n",
        "            atrous = [1] * blocks\n",
        "        elif isinstance(atrous, int):\n",
        "            # 当设置atrous=2,blocks=3时，atrous=[2,2,2]\n",
        "            # 此时表示resnet的block1,或者block2,或者block3,或者block4内的bottleneck中的3x3卷积的膨胀系数为2\n",
        "            atrous_list = [atrous] * blocks\n",
        "            atrous = atrous_list\n",
        "        # 如果atrous不是None,也不是一个整数，那么atrous被直接设定为[1,2,3]\n",
        "        # 此时表示resnet的block1,或者block2,或者block3,或者block4内的bottleneck中的3个3x3卷积的膨胀系数分别为[1,2,3]\n",
        "        \n",
        "        if stride != 1 or in_chans != out_chans * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(in_chans, out_chans * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_chans * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(in_chans, out_chans, stride=stride, atrous=atrous[0], downsample=downsample))\n",
        "        in_chans = out_chans * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(in_chans, out_chans, stride=1, atrous=atrous[i]))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        layers_list = []\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer1(x)\n",
        "        # 此时x为4倍下采样\n",
        "        layers_list.append(x)\n",
        "        x = self.layer2(x)\n",
        "        # 此时x为8倍下采样\n",
        "        layers_list.append(x)\n",
        "        x = self.layer3(x)\n",
        "        # 此时x为8倍或者16倍下采样，由本代码的123,125行的 stride_list决定\n",
        "        # stride_list[2,1,1]时，就是8倍下采样\n",
        "        # stride_list[2,2,1]时，就是16倍下采样\n",
        "        \n",
        "        layers_list.append(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.layer5(x)\n",
        "        x = self.layer6(x)\n",
        "        # 此时x为8倍或者16倍下采样，由本代码的123,125行的 stride_list决定\n",
        "        # stride_list[2,1,1]时，就是8倍下采样\n",
        "        # stride_list[2,2,1]时，就是16倍下采样\n",
        "        layers_list.append(x)\n",
        "        # return 4个feature map,分别是block1,block2,block3,block6的feature map\n",
        "        return layers_list\n",
        "\n",
        "# # 测试\n",
        "# t = torch.rand(1, 3, 64, 64)\n",
        "# test_net = ResNet_Atrous(BottleNect, [2, 2, 2, 3], atrous=[1, 2, 1])\n",
        "# out = test_net(t)\n",
        "# print(len(out))\n",
        "# print(out[-1].shape) # ([1, 2048, 4, 4])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n",
            "torch.Size([1, 2048, 4, 4])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2owXKr0Xqgd3"
      },
      "source": [
        "def resnet50_atrous(pretrained=True, os=16, **kwargs):\n",
        "    \"\"\"Constructs a atrous ResNet-50 model.\"\"\"\n",
        "    model = ResNet_Atrous(BottleNeck, [3, 4, 6, 3], atrous=[1, 2, 1], os=os, **kwargs)\n",
        "    if pretrained:\n",
        "        old_dict = model_zoo.load_url(model_urls['resnet50'])\n",
        "        model_dict = model.state_dict()\n",
        "        old_dict = {k: v for k, v in old_dict.items() if (k in model_dict)}\n",
        "        model_dict.update(old_dict)\n",
        "        model.load_state_dict(model_dict)\n",
        "    return model"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMTLVVxVqmXy"
      },
      "source": [
        "class Config:\n",
        "    # 下采样倍率\n",
        "    OUTPUT_STRIDE = 16\n",
        "    #设定ASPP模块输出的channel数\n",
        "    ASPP_OUTDIM = 256\n",
        "    # Decoder中，shortcut的1x1卷积的channel数目\n",
        "    SHORTCUT_DIM = 48\n",
        "    # Decoder中，shortcut的卷积的核大小\n",
        "    SHORTCUT_KERNEL = 1\n",
        "    # 每个像素要被分类的类别数\n",
        "    NUM_CLASSES = 21"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-admFYMq0fG"
      },
      "source": [
        "class DeeplabV3Plus(nn.Module):\n",
        "    def __init__(self, cfg, backbone=resnet50_atrous):\n",
        "        super(DeeplabV3Plus, self).__init__()\n",
        "        self.backbone = backbone(pretrained=False, os=cfg.OUTPUT_STRIDE)\n",
        "        input_channel = 512 * self.backbone.block.expansion\n",
        "        self.aspp = ASPP(input_channel, cfg.ASPP_OUTDIM, rate=16//cfg.OUTPUT_STRIDE)\n",
        "        self.dropout1 = nn.Dropout(0.5)\n",
        "        self.upsample4 = nn.UpsamplingBilinear2d(scale_factor=4)\n",
        "        self.upsample_sub = nn.UpsamplingBilinear2d(scale_factor=cfg.OUTPUT_STRIDE//4)\n",
        "\n",
        "        indim = 64 * self.backbone.block.expansion\n",
        "        self.shortcut_conv = nn.Sequential(\n",
        "                nn.Conv2d(indim, cfg.SHORTCUT_DIM, cfg.SHORTCUT_KERNEL, 1, padding=cfg.SHORTCUT_KERNEL//2,bias=False),\n",
        "                nn.BatchNorm2d(cfg.SHORTCUT_DIM),\n",
        "                nn.ReLU(inplace=True),\n",
        "        )\n",
        "        self.cat_conv = nn.Sequential(\n",
        "                nn.Conv2d(cfg.ASPP_OUTDIM+cfg.SHORTCUT_DIM, cfg.ASPP_OUTDIM, 3, 1, padding=1,bias=False),\n",
        "                nn.BatchNorm2d(cfg.ASPP_OUTDIM),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout(0.5),\n",
        "                nn.Conv2d(cfg.ASPP_OUTDIM, cfg.ASPP_OUTDIM, 3, 1, padding=1, bias=False),\n",
        "                nn.BatchNorm2d(cfg.ASPP_OUTDIM),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout(0.1),\n",
        "        )\n",
        "        self.cls_conv = nn.Conv2d(cfg.ASPP_OUTDIM, cfg.NUM_CLASSES, 1, 1, padding=0)\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 利用backbone生成block1,2,3,4,5,6,7的feature maps\n",
        "        layers = self.backbone(x)\n",
        "        # layers[-1]是block7输出的feature map相对于原图下采样了16倍\n",
        "        # 把block7的输出送入aspp\n",
        "        feature_aspp = self.aspp(layers[-1])\n",
        "        feature_aspp = self.dropout1(feature_aspp)\n",
        "        # 双线行插值上采样4倍\n",
        "        feature_aspp = self.upsample_sub(feature_aspp)\n",
        "\n",
        "        # layers[0],是block1输出的featuremap，相对于原图下采样的4倍，我们将它送入1x1x48的卷积中\n",
        "        feature_shallow = self.shortcut_conv(layers[0])\n",
        "        # aspp上采样4倍，变成相对于原图下采样4倍，与featue _shallow 拼接融合\n",
        "        feature_cat = torch.cat([feature_aspp, feature_shallow],1)\n",
        "        result = self.cat_conv(feature_cat)\n",
        "        result = self.cls_conv(result)\n",
        "        result = self.upsample4(result)\n",
        "        return result"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaN4q-E0q7wI"
      },
      "source": [
        "## 作业部分：完成ASPP\n",
        "ASPP定义；输入为512*expansion,输出为256；其中经过了5个通道:\n",
        "\n",
        "\n",
        "1.   cbr，卷积核为1x1\n",
        "2.   cbr，卷积核为3x3，dilation=6\n",
        "3.   cbr，卷积核为3x3，dilation=12\n",
        "4.   cbr，卷积核为3x3，dilation=18\n",
        "5.   GAP->cbr,卷积核为1x1->上采样回输入hw\n",
        "\n",
        "然后进行通道维度concate，变成256*5通道维度，再接一个cbr，卷积核为1x1用来调整通道至256大小。\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKuN7mOlq7BW"
      },
      "source": [
        "class ASPP(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, rate=1):\n",
        "        super().__init__()\n",
        "        d_list = [6*rate*x for x in range(1, 4)]\n",
        "        self.p1 = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, kernel_size=1, bias=False),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(True)\n",
        "        )\n",
        "        self.d_blocks = nn.ModuleList()\n",
        "        for d in d_list: # 6, 12, 18\n",
        "            self.d_blocks.append(conv3x3(in_ch, out_ch, atrous=d))\n",
        "        self.p5 = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Conv2d(in_ch, out_ch, kernel_size=1, bias=False),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(True)\n",
        "        )\n",
        "        self.final_conv = nn.Conv2d(out_ch*5, out_ch, kernel_size=1, bias=False)\n",
        "    def p5_upsample(self, p5_feature, h, w, mode='bilinear'):\n",
        "        b, c, _, _ = p5_feature.shape\n",
        "        if mode == 'expand': # 1x1矩阵的复制扩张\n",
        "            out = p5_feature.expand(b, c, h, w)\n",
        "        elif mode == 'deconv': # 使用反卷积上采样\n",
        "            assert h == w, '只有在输入图片长宽相等情况下才能使用此方法！'\n",
        "            upsample = nn.Sequential(\n",
        "                nn.ConvTranspose2d(c, c, kernel_size=h, stride=h, bias=False),\n",
        "                nn.BatchNorm2d(c),\n",
        "                nn.ReLU(True)\n",
        "            )\n",
        "            out = upsample(p5_feature)\n",
        "        else: # 默认使用双线性插值上采样\n",
        "            out = F.interpolate(p5_feature, size=(h, w), mode='bilinear', align_corners=True)\n",
        "        return out\n",
        "    def forward(self, x):\n",
        "        _, _, h, w = x.shape\n",
        "        p1_feature = self.p1(x)\n",
        "        p2_feature = self.d_blocks[0](x)\n",
        "        p3_feature = self.d_blocks[1](x)\n",
        "        p4_feature = self.d_blocks[2](x)\n",
        "        p5_feature = self.p5(x)\n",
        "        p5_feature = self.p5_upsample(p5_feature, h, w, mode='bilinear')\n",
        "        cat_feature = torch.cat([p1_feature, p2_feature, p3_feature, p4_feature, p5_feature], dim=1)\n",
        "        ret = self.final_conv(cat_feature)\n",
        "        return ret\n",
        "\n",
        "# # 测试\n",
        "# t = torch.rand(2, 3, 8, 8)\n",
        "# test_aspp = ASPP(3, 4, rate=1)\n",
        "# out = test_aspp(t)\n",
        "# print(out.shape)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZBQl0gKPNJm",
        "outputId": "af3ca73a-ea19-410d-b436-b0e3d8b6b46c"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    cfg = Config()\n",
        "    model = DeeplabV3Plus(cfg, backbone=resnet50_atrous)\n",
        "    x = torch.randn((2, 3, 128, 128), dtype=torch.float32)\n",
        "    y = model(x)\n",
        "    print(y.shape)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 21, 128, 128])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}